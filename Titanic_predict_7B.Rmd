---
title: 'Titanic - Kaggle - Prediction'
subtitle: "Prediction attempts"
author:  "Bruno Fischer Colonimos"
date: "`r format(Sys.Date(), '%d %B %Y')`"
# header-includes: \usepackage{graphicx} # for unmodded template
fontsize: 12pt
urlcolor: "blue"   ## external
linkcolor: "red" ## internal
documentclass: article
classoption: a4paper
geometry: "left=1.5cm,right=1.5cm,top=1.5cm,bottom=2cm,footskip=1cm"
footer: \thetitle \ \textemdash \ \thepage 
output:
  # bookdown::pdf_document2:
  pdf_document:
    # template: test_latex_temp
    template: latex_temp2.latex
    highlight: monochrome
    number_sections: yes
    toc: yes
    toc_depth: 4
    # keep_tex: true
    fig_caption: yes
    
  # html_document:
  #   number_sections: yes
  #   toc: yes
  #   toc_depth: 4
  #   fig_caption: yes
---

***************************


<!-- Some Inline HTML (CSS) , formatting tables -->

<style>

table {
    width: 100%;
    border-top-style: solid;
    border-top-width: medium;
    border-top-color: initial;
    border-bottom-style: solid;
    border-bottom-width: medium;
    border-bottom-color: initial;
}

</style>

<!-- End Inline HTML -->



Preliminary code
================

```{r globalopts}
# Global options
globalseed <- 98765 # unique seed for reproducibility
percenttraining <- 0.75 # percentage of 'trainingset' to put in truetrainingset

nfolds <- 10 # k = number of folds fork-folds crossvalidation
baserf <- 20 # number of random forests models to stack together

bwtheme <- TRUE
specialpalette <- TRUE # controls the colour of the plots
showarning <- TRUE # show warnings (deleted empty rows...)
datmis <- "Ukn"
base_cache <- TRUE
stk_cache <- TRUE

```


## Required packages (install before running)

"caret", "ggplot2", pander, doParallel    



## Libraries and auxiliary code (install before running)

(Not fully echoed here)


```{r libs, echo =FALSE, warning=FALSE, message=FALSE, results='hide'}
# libraries
library(pander)
library(ggplot2)
library(dplyr)
library(knitr, quietly = TRUE)
library(caret, quietly = TRUE )
library(parallel, quietly = TRUE) # parallel computing
library(doParallel, quietly = TRUE)  # parallel computing
library(rpart, quietly = TRUE)
library(randomForest, quietly = TRUE)
library(MASS, quietly = TRUE)
library(klaR, quietly = TRUE)
library(fastAdaboost, quietly = TRUE) # adaboost
library(e1071, quietly = TRUE)
library('RANN', quietly = TRUE) # for knnimpute


# Source preparatory code
# ========================

source("preparation.R")

# Set aliases
knitr::set_alias(w = "fig.width", a = "fig.asp")

# default options
knitr::opts_chunk$set(echo = FALSE, fig.width = w.13, fig.asp = a.11 , fig.pos = 'H', fig.align = "center", fig.show = "hold")


```

Data
=====

Get it
-------

```{r dataget}
# read
datadir <-  "data"
fname <-  "train.csv"
tdf <- read.csv(file.path(datadir, fname), stringsAsFactors = FALSE)

```

Variables organization {#variables}
-----------------------


Variables                 type        Values                Treatment
------------------------  --------    -------------------   ------------------
__Demographic variables__
    * Sex                  String       female ; male       Make factor
    * Age                  numeric
    * Agestat              factor      enfant/ado/adulte    new:
__Family context__
    * SibSp                numeric                          Combined ->
    * Parch                numeric                          Combined ->
    * Famly                numeric                          new: SibSp + Parch
__Relationship to ship__
    * Pclass                             1,2,3              Make factor
    * ticket                            ticket number       not used
    * Fare                 numeric
    * Cabin                             Cabin nbr           not used
    * Embark               Factor       C = Cherbourg,          
                                        Q = Queenstown, 
                                        S = Southampton
__Survival__              
    * survived             binary        0/1                Make factor

:`r tabcap(chunklabel = "dataorg", "Data organization")`


Data modifications {#modifs}
----------------------------

* Make `Survived` , `Pclass` and `Embark`   factors, 
* Create `Famly` = `SibSp + Parch` 


```{r datamod, warning=FALSE}

# fonction de modification des donn√©es:

mod_data <- function(dframe){
        # factor survived
        sf <- factor(dframe$Survived, labels=c("No", "Yes"))
        dframe$Survived <- sf
        # makefactor Pclass
        dframe$Pclass <- factor(dframe$Pclass)
        
        # combine SibSp + Parch
        dframe$Famly <- dframe$SibSp + dframe$Parch
        
        # Embarked
        dframe$Embarked[which(dframe$Embarked == "")] <- datmis
        dframe$Embarked <-  factor(dframe$Embarked)
        
        # Sex
        dframe$Sex <- factor(dframe$Sex)
        
        
        # ajout de variables
        dframe <- dframe %>%
                mutate(sex.class = paste(Sex, Pclass, sep  = "."))
        
        # age status
        dframe$agestat <- cut(dframe$Age, breaks=c(0,12,18,100), labels=c("child", "teen", "adult"))
        # code missing values 'datmis'
        dframe$agestat <- as.character(dframe$agestat)
        dframe$agestat <- ifelse(is.na(dframe$agestat), datmis, dframe$agestat)
        dframe$agestat <- factor(dframe$agestat)
        
        ### Cleaning: transforming covariates, removing superfluous variables
        # ------------------------------------------
        # let_ticket = are letters included in the ticket number
        dframe$letticket <- as.numeric(substr(dframe$Ticket,start = 1, stop = 1 ) %in% LETTERS)
        
        # hascabin is the cabin number known?
        dframe$hascabin <- as.numeric(dframe$Cabin != "")
        # Deck (from https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/)
        dframe$Deck <- factor(ifelse( dframe$Cabin != "", 
                           substr(dframe$Cabin,start = 1,stop = 1), 
                           datmis))
        # return dframe
        return(dframe)
}

```

### Cleaning: transforming covariates, removing superfluous variables

```{r dataclean1, warning= FALSE}

clean_data <- function(dframe) {
        ### Dummy vars 
        # Representing the factors with dummies
        dframe$Deck <- relevel(dframe$Deck, ref = datmis)
        dframe$Pclass <- relevel(dframe$Pclass, ref = "3")
        dframe$Embarked <- relevel(dframe$Embarked, ref = datmis)
        
        dummies <- dummyVars(Survived ~ ., 
                             data = dframe[c("Survived", "Pclass", "Sex", "Embarked", "Deck" )],
                             fullRank = TRUE) # ! attention
        
        dumvars <- predict(dummies, newdata = dframe[c("Survived", "Pclass", "Sex", "Embarked", "Deck" )])
        
        dumvars <- as.data.frame(dumvars)

        # add dummies to the data
        dframe <- cbind(dframe, dumvars)
        
        # select variables to avoid collinearity
        dframe <- dframe[, c("Survived", 
                "Age", "SibSp" ,"Parch", "Fare", 
                # "Cabin", 
                # "Embarked",   
                # "letticket",  
                "hascabin", 
                "Pclass.1" , "Pclass.2", 
                 "Sex.male",  
                "Embarked.C", "Embarked.Q", "Embarked.S", 
                # "Embarked.Ukn",
                "Deck.A", "Deck.B", "Deck.C", "Deck.D", "Deck.E", "Deck.F", "Deck.G" #, "Deck.T"
                )]
        return(dframe)
}

```

```{r preprocSynth}

tdf2 <- clean_data(mod_data(tdf))

```

### Splitting data

```{r datasplit}
set.seed(globalseed)
intrain <- createDataPartition(y=tdf2$Survived,
                               p= percenttraining,
                               list = FALSE)

trainingset <- tdf2[intrain,]
validationset <- tdf2[-intrain,]
```



### inputting missing values (age) based on trainingset only

```{r inputmissing}
set.seed(globalseed)
preProcValues <- preProcess(trainingset, method = c("knnImpute","center","scale"))


trainingmis <- predict(preProcValues, trainingset)
validationmis <- predict(preProcValues, validationset)

# verifications
# sum(is.na(trainingset$Age))
# length(trainingset$Age)
# sum(is.na(trainingmis$Age))
# length(trainingmis$Age)

# imputation
trainingset$Age <- trainingmis$Age
validationset$Age <- validationmis$Age
```


### introducing interactions (no, not now, something doesn't work)

```{r addinteraction, eval=FALSE}

namecol <- colnames(trainingset)
# namecolp <- namecol[-1]


# function to do the products
makeprods <- function(basevar, # the name (string) of the variable to multiply
                      prodstodo, # vector of names of the columns by which to multiply  
                      dframe) {  # the dataframe containing the vars
        listp <- lapply(prodstodo,
                        FUN = function(factname){
                                dframe[[basevar]] * dframe[[factname]]
                        } )
        vnames <- sapply(prodstodo,
                         FUN=function(factname){
                                 paste(basevar, factname, sep = "_")
                         } )
        dftp <- as.data.frame(listp)
        colnames(dftp) <- vnames
        dftp # return the dataframe of products
}


allprods <- function(vbv, vprods, dframe){
        # init dummy column
        A <- data.frame(dummy = numeric(nrow(dframe)))
        # products
        P <- lapply(1:length(vbv),
                    FUN = function(idx){
                            makeprods(vbv[idx], 
                                      vprods[(idx+1):length(vprods)],
                                      dframe = dframe)
                    } )
        # combine all columns
        A <- Reduce(f = function(dfx, dfy){cbind(dfx, dfy)},
               x = P,
               init = A)
        A[-1] # jettison dummy col and return
}




# apply
makeinter <- function(dframe) {
        namecol <- colnames(dframe)
        intr <- allprods(vbv = namecol[2:12], 
                         vprods = namecol[-(1:8)], 
                         dframe = dframe)
        # add interaction cols at the end
        cbind(dframe, intr)
}

trainingset2 <- makeinter(trainingset) #***************
validationset <- makeinter(validationset)

# remove lin combinations

flc <- findLinearCombos(trainingset[-1])
trainingset <- trainingset[ ,-flc$remove]
validationset <- validationset[ ,-flc$remove]

```






====================

Tools
-----

```{r modelbuildtools}
# functions to record modeling attempts
recordmod <- local({
        recdf <- data.frame(
                Name = character(),
                Method = character(),
                Preprocess = character(),
                Best.tune = character(),
                Acc.CV = numeric(),
                Acc.Valid = numeric(),
                Model.name = character(),
                stringsAsFactors = FALSE)
        reclist <- list(recdf)
        init <- function(i = 1){ # i = the record "track"
                recdf <- data.frame(
                        Name = character(),
                        Method = character(),
                        Preprocess = character(),
                        Best.tune = character(),
                        Acc.CV = numeric(),
                        Acc.Valid = numeric(),
                        Model.name = character(),
                        stringsAsFactors = FALSE)
                reclist <- reclist
                reclist[[i]] <- recdf
                reclist <<- reclist # update list in parent env
        }
        new <- function(i = 1, # the record "track" = either an integer or a name (string)
                        Name ="",
                        Method = "" ,
                        Preprocess ="" ,
                        Best.tune ="",
                        Acc.CV = 0 ,
                        Acc.Valid = 0,
                        Model.name = "") {
                reclist <- reclist
                recdf <- reclist[[i]]
                newrow <- data.frame(Name = Name,
                                     Method = Method,
                                     Preprocess = Preprocess,
                                     Best.tune = Best.tune,
                                     Acc.CV = Acc.CV ,
                                     Acc.Valid = Acc.Valid,
                                     Model.name = Model.name,
                                     stringsAsFactors = FALSE )
                recdf <- rbind(recdf, newrow)
                reclist[[i]] <- recdf # update
                reclist <<- reclist # update
        }
        get <- function(i = 1) reclist[[i]]
        # export funtions
        list(init = init,
             new=new,
             get=get)
})

# initialize tracks 1 and 2
recordmod$init(1)
recordmod$init(2)

```






Model Building
--------------


### Random Forests


```{r modelbuildrf, cache=base_cache, dependson="dataclean1"}

# _______________________________
# Random Forests

fit_many_modls <- function(traindf, numfit, validate = FALSE, validf = NULL) {
        
        # fit one model
        makefit_rf <- function(i) {
                # set parallel proc 
                cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
                registerDoParallel(cluster)
                # random seed
                
                set.seed(globalseed + i)
                modlname <- paste0("RF",i)
                #fit
                modl <- train(Survived ~ . , data = traindf,
                              method = "rf",
                              trControl = trainControl(method = "cv",
                                                       number = nfolds))
                
                # stop parallel proc.
                stopCluster(cluster)
                registerDoSEQ()
                
                # Record model performance
                # 
                # if validate (try on validation set)
                if (validate) {
                        cm <- confusionMatrix(data = predict( modl , newdata=validf, type="raw"),
                                      reference = validf$Survived)
                        accvalid <- round(cm$overall["Accuracy"], 3)
                } else {accvalid <- NA_real_}
                
                
                recordmod$new(Name = modlname, 
                              Method = modl$method, 
                              Preprocess = "None",
                              Best.tune = paste0(colnames(modl$bestTune)[1], " = ", modl$bestTune[1]),
                              Acc.CV = round(max(modl$results$Accuracy), 3),
                              Acc.Valid = accvalid, 
                              Model.name = modlname )
                # Return fitted model
                modl
        }
        
        # make many models in a loop:
        
        # liste des mod√®les
        listmodls <- as.list(1:numfit)
        
        for (i in 1:numfit){
                print(i) # dbg *************************
                listmodls[[i]] <- makefit_rf(i)
        }
        return(listmodls)
}

rf_fits <- fit_many_modls(traindf=trainingset, 
                          numfit = baserf, 
                          validate = TRUE, 
                          validf = validationset)

```



Summary of models
---------------

```{r}
kable(recordmod$get(), row.names = FALSE, caption = "Base models accuracy")
```


Stacking models
---------------

### Base models to stack
rf_fits



### predictions from base models

```{r basepreds, warning=FALSE}

# length(rf_fits)



stack_predictions <- function(listfits, dset) {
        listpred <- lapply(listfits,
                           FUN = function(modl) {
                                   predict(modl, newdata = dset, type = "prob")   
                           }
        )
        dpred <- as.data.frame(listpred)
        dpred <- dpred[ , 1:length(listpred) %% 2 != 0]
        colnames(dpred) <- paste0("P", 1:length(listpred))
        return(cbind(data.frame(Survived=dset$Survived),
                      dpred ) )
}

# trainingset
stk_train_df <- stack_predictions(listfits = rf_fits, 
                                   dset = trainingset )
stk_valid_df <- stack_predictions(listfits = rf_fits, 
                                   dset = validationset )

```

The base predictions are generated as follows:
```{r, ref.label="basepreds", echo = TRUE, eval=FALSE}

```



### stacked predictions

#### Combined With RF


```{r modelbuild_stk_rf, cache=stk_cache}

# stkrf Stacked preds with rf
# 
# parallel processing
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)


set.seed(globalseed)
modl <- modstkrf <- train(Survived ~ . , data = stk_train_df,
                        method = "rf",
                        trControl = trainControl(method = "cv",
                                                 number = nfolds))

# stop parallel proc.
stopCluster(cluster)
registerDoSEQ()
```



```{r modelbuild_stk_rf_rec}

# record attempt

cm <- confusionMatrix(data = predict( modl , newdata=stk_valid_df, type="raw"),
                reference = validationset$Survived)

recordmod$new( i = 2,
              Name = "Stacked RF", 
              Method = modl$method, 
              Preprocess = "None",
              Best.tune = paste0(colnames(modl$bestTune)[1], " = ", modl$bestTune[1]),
              Acc.CV = round(max(modl$results$Accuracy),3),
              Acc.Valid = round(cm$overal["Accuracy"],3),
              Model.name = "modstkrf" )

```



#### Combined With RF_PCA


```{r modelbuild_stk_rf_pca, cache=stk_cache}

# stkrf Stacked preds with rf
# 
# parallel processing
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)


set.seed(globalseed)
modl <- modstkrfpca <- train(Survived ~ . , data = stk_train_df,
                        method = "rf",
                        preProcess="pca",
                        trControl = trainControl(method = "cv",
                                                 number = nfolds))

# stop parallel proc.
stopCluster(cluster)
registerDoSEQ()
```



```{r modelbuild_stk_rf_pca_rec}

# record attempt

cm <- confusionMatrix(data = predict( modl , newdata=stk_valid_df, type="raw"),
                reference = validationset$Survived)

recordmod$new( i = 2,
              Name = "Stacked RF_PCA", 
              Method = modl$method, 
              Preprocess = "None",
              Best.tune = paste0(colnames(modl$bestTune)[1], " = ", modl$bestTune[1]),
              Acc.CV = round(max(modl$results$Accuracy),3),
              Acc.Valid = round(cm$overal["Accuracy"],3),
              Model.name = "modstkrfpca" )

```




#### Combined With adaboost


```{r modelbuild_stk_ada, cache=stk_cache}

# stkrf Stacked preds with rf
# 
# parallel processing
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)


set.seed(globalseed)
modl <- modstk_ada <- train(Survived ~ . , data = stk_train_df,
                        method = "adaboost",
                        trControl = trainControl(method = "cv",
                                                 number = nfolds))

# stop parallel proc.
stopCluster(cluster)
registerDoSEQ()
```



```{r modelbuild_stk_ada_rec}
# record attempt
cm <- confusionMatrix(data = predict( modl , newdata=stk_valid_df, type="raw"),
                reference = validationset$Survived)

recordmod$new( i = 2,
              Name = "Stacked adaboost", 
              Method = modl$method, 
              Preprocess = "None",
              Best.tune = paste0(colnames(modl$bestTune)[1], " = ", modl$bestTune[1]),
              Acc.CV = round(max(modl$results$Accuracy),3),
              Acc.Valid = round(cm$overal["Accuracy"],3),
              Model.name = "modstk_ada" )

```



```{r}
kable(recordmod$get(i=2), row.names = FALSE, caption = "Stacked RF")
```


